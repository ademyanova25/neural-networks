{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the tensorflow package\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1IeLm6hQ9x6v"
   },
   "outputs": [],
   "source": [
    "# в первую очередь подключим numpy и библиотеку copy, которая понадобится, чтобы сделать deepcopy ряда элементов\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiq0R-hnCu7j"
   },
   "source": [
    "# IMDB reviews (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ch2IbkRVCI8P"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2OjBlxbTC3Nx"
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 80\n",
    "batch_size = 50 # увеличьте значение для ускорения обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qU_kiLbC2jK",
    "outputId": "0e06ad04-2342-4bf3-d483-3a8f7fd055f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtJSwOPDC7__",
    "outputId": "f4977635-7bbf-4c44-dcfc-ec7f60b569cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-z0-a_pFCwE",
    "outputId": "167b86e1-a7ac-4d85-92ef-28a9e25f9f9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGAsy1MFDEVZ",
    "outputId": "43a45e8a-6e44-4ed6-e0a1-6b85b3d0fd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s4YPiv4OFQJX"
   },
   "outputs": [],
   "source": [
    "layer = Embedding(max_features, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e9AmlPFXyIg1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([80, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x_train[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuCf2ixNDJ8m",
    "outputId": "56b46e29-4ad0-4dcd-918e-2887c954398e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n"
     ]
    }
   ],
   "source": [
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pKTWAEViFOdj"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STDbV391GfDO",
    "outputId": "68b470ca-7816-4526-a9f3-799ca12546c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения...\n",
      "500/500 [==============================] - 55s 105ms/step - loss: 0.4329 - accuracy: 0.7921 - val_loss: 0.3640 - val_accuracy: 0.8432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee252e0520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09mnjJl0GlB7",
    "outputId": "e9673b14-5e9e-4809-e1e4-855afc0e00f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3640 - accuracy: 0.8432\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DY6eThlJGnIs",
    "outputId": "181a131c-7453-4e9f-e5cf-f70a3bceba14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат при тестировании: 0.36397191882133484\n",
      "Тестовая точность: 0.8431599736213684\n"
     ]
    }
   ],
   "source": [
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 200\n",
    "\n",
    "batch_size = 50 # увеличьте значение для ускорения обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 47s 90ms/step - loss: 0.3939 - accuracy: 0.8154 - val_loss: 0.3218 - val_accuracy: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee276e4af0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=50,\n",
    "          epochs=1, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3218 - accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат при тестировании: 0.3218313455581665\n",
      "Тестовая точность: 0.8682399988174438\n"
     ]
    }
   ],
   "source": [
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xLGyQjYG3eq"
   },
   "source": [
    "# Генерация текста на основе книжки «Алиса в стране чудес»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "99v6TBSqHBjU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0FoMKffgHIyR"
   },
   "outputs": [],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set(text)\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xlcUCnMRHfzk"
   },
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "TQZaEpb-Hlyg"
   },
   "outputs": [],
   "source": [
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L3y9LfmHywZ",
    "outputId": "1192ea8e-a540-4367-9171-4663d2535497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Анна\\AppData\\Local\\Temp\\ipykernel_3736\\1321165275.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
      "C:\\Users\\Анна\\AppData\\Local\\Temp\\ipykernel_3736\\1321165275.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "FWqwrcHiH6gw"
   },
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 10 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsGE7YUdITrA",
    "outputId": "7e54fc46-8b4d-498b-ec84-0399313d11f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "1241/1241 [==============================] - 9s 6ms/step - loss: 2.3175\n",
      "Генерация из посева: very momen\n",
      "very moment of the was in the was in the was in the was in the was in the was in the was in the was in the was==================================================\n",
      "Итерация #: 1\n",
      "1241/1241 [==============================] - 7s 6ms/step - loss: 1.9183\n",
      "Генерация из посева: toop? soup\n",
      "toop? soup the dont of the dont of the dont of the dont of the dont of the dont of the dont of the dont of the==================================================\n",
      "Итерация #: 2\n",
      "1241/1241 [==============================] - 7s 5ms/step - loss: 1.7562\n",
      "Генерация из посева: oviding it\n",
      "oviding it was the grown the reat the reat the reat the reat the reat the reat the reat the reat the reat the ==================================================\n",
      "Итерация #: 3\n",
      "1241/1241 [==============================] - 6s 5ms/step - loss: 1.6495\n",
      "Генерация из посева: walked off\n",
      "walked off the mormons and the mormons and the mormons and the mormons and the mormons and the mormons and the==================================================\n",
      "Итерация #: 4\n",
      "1241/1241 [==============================] - 6s 5ms/step - loss: 1.5688\n",
      "Генерация из посева: ce whisper\n",
      "ce whisper and the morme the morme the morme the morme the morme the morme the morme the morme the morme the m==================================================\n",
      "Итерация #: 5\n",
      "1241/1241 [==============================] - 7s 5ms/step - loss: 1.5050\n",
      "Генерация из посева: rush at al\n",
      "rush at all the think the more the more the more the more the more the more the more the more the more the mor==================================================\n",
      "Итерация #: 6\n",
      "1241/1241 [==============================] - 6s 5ms/step - loss: 1.4518\n",
      "Генерация из посева: read-and-b\n",
      "read-and-but she had not it was the caterpillar the caterpillar the caterpillar the caterpillar the caterpilla==================================================\n",
      "Итерация #: 7\n",
      "1241/1241 [==============================] - 8s 6ms/step - loss: 1.4088\n",
      "Генерация из посева: ter glarin\n",
      "ter glaring and the stard and the more the mock turtle as she said to the court, and the more the mock turtle ==================================================\n",
      "Итерация #: 8\n",
      "1241/1241 [==============================] - 8s 6ms/step - loss: 1.3701\n",
      "Генерация из посева: mouths. so\n",
      "mouths. so she went on the tried the time the tried the time the tried the time the tried the time the tried t==================================================\n",
      "Итерация #: 9\n",
      "1241/1241 [==============================] - 7s 6ms/step - loss: 1.3377\n",
      "Генерация из посева: e use of t\n",
      "e use of the words in a mouse and she was not a mouse to be the door of the door of the door of the door of th"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 256, 256\n",
    "NUM_ITERATIONS = 10 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 10\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 24s 37ms/step - loss: 2.5317\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 23s 36ms/step - loss: 2.0783\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.8955\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.7564\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.6523\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 1.5642\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 23s 37ms/step - loss: 1.4945\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 23s 37ms/step - loss: 1.4342\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 25s 41ms/step - loss: 1.3831\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 24s 39ms/step - loss: 1.3367\n",
      "Генерация из посева: and then, \n",
      "and then, and the project gutenberg-tm electronic works in a long to the project gutenberg-tm electronic works==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 23s 37ms/step - loss: 1.2956\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.2571\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.2193\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 1.1850\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 25s 40ms/step - loss: 1.1521\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 27s 43ms/step - loss: 1.1231\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 26s 42ms/step - loss: 1.0906\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 26s 41ms/step - loss: 1.0595\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 26s 42ms/step - loss: 1.0310\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 32s 51ms/step - loss: 1.0018\n",
      "Генерация из посева: g her paws\n",
      "g her paws of the states of the states of the states of the states of the states of the states of the states o==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 31s 50ms/step - loss: 0.9780\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 31s 50ms/step - loss: 0.9523\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 32s 52ms/step - loss: 0.9288\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 37s 59ms/step - loss: 0.9051\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 35s 56ms/step - loss: 0.8814\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 31s 50ms/step - loss: 0.8611\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 29s 47ms/step - loss: 0.8407\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 28s 45ms/step - loss: 0.8216\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 28s 45ms/step - loss: 0.8022\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 28s 45ms/step - loss: 0.7857\n",
      "Генерация из посева: rdly worth\n",
      "rdly worth the whole party as well as she could not think of the mock turtle went on, there was a mouse that h==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 27s 43ms/step - loss: 0.7693\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 30s 49ms/step - loss: 0.7528\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.7391\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 28s 46ms/step - loss: 0.7230\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 35s 56ms/step - loss: 0.7110\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.6969\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.6842\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.6697\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 34s 55ms/step - loss: 0.6619\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 28s 46ms/step - loss: 0.6502\n",
      "Генерация из посева: w treacle \n",
      "w treacle out of a sea, and he there was nothing so mecticl whe itherg to ask dew dormations to the project gu==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 28s 46ms/step - loss: 0.6385\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 31s 50ms/step - loss: 0.6306\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 37s 59ms/step - loss: 0.6200\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.6112\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 34s 55ms/step - loss: 0.6025\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.5971\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.5902\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.5792\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 33s 53ms/step - loss: 0.5741\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 33s 53ms/step - loss: 0.5640\n",
      "Генерация из посева:  english);\n",
      " english); now im opening out the fant a wheld of any money paid by a user who was marked the king, and the pa==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 36s 59ms/step - loss: 0.5619\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 38s 62ms/step - loss: 0.5549\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 39s 62ms/step - loss: 0.5486\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 39s 62ms/step - loss: 0.5409\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 32s 52ms/step - loss: 0.5378\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 28s 46ms/step - loss: 0.5305\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 30s 49ms/step - loss: 0.5291\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 33s 53ms/step - loss: 0.5218\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 34s 54ms/step - loss: 0.5176\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.5136\n",
      "Генерация из посева:  a very me\n",
      " a very melancholy air, he dont goong to do that, said the duchess said in a low voice, to the concupton trema==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 38s 61ms/step - loss: 0.5116\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 35s 57ms/step - loss: 0.5060\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 29s 47ms/step - loss: 0.5046\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4954\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4926\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 28s 44ms/step - loss: 0.4938\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 37s 60ms/step - loss: 0.4873\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 39s 62ms/step - loss: 0.4826\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 38s 62ms/step - loss: 0.4816\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 38s 61ms/step - loss: 0.4791\n",
      "Генерация из посева: or soldier\n",
      "or soldiers, who of course not, alice replied very readily: but then--i shouldnt be in bills place for ow, wil==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 33s 54ms/step - loss: 0.4791\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 31s 51ms/step - loss: 0.4742\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 27s 44ms/step - loss: 0.4721\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 27s 43ms/step - loss: 0.4656\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 36s 59ms/step - loss: 0.4650\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 41s 66ms/step - loss: 0.4627\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 39s 63ms/step - loss: 0.4598\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 30s 49ms/step - loss: 0.4587\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4568\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 34s 54ms/step - loss: 0.4550\n",
      "Генерация из посева: h the cook\n",
      "h the cook turn-- as anotiling them her adventures in wonderland *** ***** this file should be named 11-0.txt ==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.4540\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 37s 60ms/step - loss: 0.4495\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 37s 60ms/step - loss: 0.4474\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.4466\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 36s 58ms/step - loss: 0.4455\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 36s 59ms/step - loss: 0.4440\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 36s 57ms/step - loss: 0.4408\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 33s 53ms/step - loss: 0.4393\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 33s 54ms/step - loss: 0.4348\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 27s 44ms/step - loss: 0.4364\n",
      "Генерация из посева: le is blow\n",
      "le is blown out, for she felt that the mouse was speaking, and the moral of that is--take care of the sort. ne==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 29s 46ms/step - loss: 0.4371\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 28s 45ms/step - loss: 0.4298\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 29s 47ms/step - loss: 0.4321\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4324\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4267\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4278\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 27s 44ms/step - loss: 0.4267\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 29s 47ms/step - loss: 0.4253\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 29s 47ms/step - loss: 0.4249\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 30s 48ms/step - loss: 0.4237\n",
      "Генерация из посева: , do copyr\n",
      ", do copyright laws of the soldiers were all tried at ye hishore; that dreamable were anl talking to herself, "
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lesson 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
